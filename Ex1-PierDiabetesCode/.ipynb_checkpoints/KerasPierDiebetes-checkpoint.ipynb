{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ace3bce488fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#选择随机数种子\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import pandas as pd\n",
    "#选择随机数种子\n",
    "seed=7\n",
    "#使用随机数可以使得机器学习算法具有随机过程，可以运行相同的代码一次又一次,得到相同的结果\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f124365bd53d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#加载数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"diabetes.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#将数据分成输入和输出两组，进行交叉验证。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#前8个特征值为输入X，第九个特征值outcome为输出Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#加载数据\n",
    "dataset=pd.read_csv(\"diabetes.csv\")\n",
    "#将数据分成输入和输出两组，进行交叉验证。\n",
    "#前8个特征值为输入X，第九个特征值outcome为输出Y\n",
    "X=dataset.iloc[:,0:8]\n",
    "Y=dataset.iloc[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建模型\n",
    "model=Sequential()#实例化Sequential 模型对象\n",
    "#input_dim设置输入层数量，设置为8代表8个输入变量;第一个参数为本层神经元的数量\n",
    "#init=uniform表示权重初始化成一个服从均匀分布的小随机数。Keras 标准均匀分布权重初始值[0,0.5];\n",
    "#init=normal则表示从高斯分布（正态分布）中产生一个小的随机数进行权重初始化。\n",
    "#activation='relu'使用线性整流函数relu，sigmoid是S型函数作为激活函数\n",
    "model.add(Dense(12,input_dim=8,kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dense(8,kernel_initializer='uniform',activation='relu'))\n",
    "model.add(Dense(1,kernel_initializer='uniform',activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#编译模型\n",
    "#定义损失函数和优化算法以及需要收集的数据，‘binary_crossentropy’错误的对数作为损失函数，adam作为优化算法\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s 699us/step - loss: 0.4796 - acc: 0.7878\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 602us/step - loss: 0.4599 - acc: 0.7786\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 601us/step - loss: 0.4579 - acc: 0.7773\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 422us/step - loss: 0.4475 - acc: 0.8099\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 474us/step - loss: 0.4461 - acc: 0.7982\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 388us/step - loss: 0.4607 - acc: 0.7904\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 455us/step - loss: 0.4443 - acc: 0.8138\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 581us/step - loss: 0.4440 - acc: 0.7839\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 490us/step - loss: 0.4480 - acc: 0.7839\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 510us/step - loss: 0.4449 - acc: 0.8008\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 453us/step - loss: 0.4358 - acc: 0.8034\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 1s 741us/step - loss: 0.4386 - acc: 0.7956\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 1s 853us/step - loss: 0.4435 - acc: 0.7969\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 443us/step - loss: 0.4382 - acc: 0.8099\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.4461 - acc: 0.7878\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 351us/step - loss: 0.4362 - acc: 0.8034\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 1s 758us/step - loss: 0.4418 - acc: 0.7878\n",
      "Epoch 18/150\n",
      "390/768 [==============>...............] - ETA: 0s - loss: 0.4537 - acc: 0.7846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/x/anaconda3/envs/ML/lib/python3.5/site-packages/keras/callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.127085). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 621us/step - loss: 0.4456 - acc: 0.7969\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 404us/step - loss: 0.4413 - acc: 0.7943\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 419us/step - loss: 0.4335 - acc: 0.8086\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 339us/step - loss: 0.4328 - acc: 0.7982\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 379us/step - loss: 0.4273 - acc: 0.8008\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 428us/step - loss: 0.4357 - acc: 0.7904\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 1s 753us/step - loss: 0.4245 - acc: 0.8047\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 403us/step - loss: 0.4349 - acc: 0.7891\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 1s 762us/step - loss: 0.4255 - acc: 0.7995 3s - loss: 0.3928 - ac\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 443us/step - loss: 0.4309 - acc: 0.7839\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 469us/step - loss: 0.4293 - acc: 0.7904\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 513us/step - loss: 0.4328 - acc: 0.7982\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 555us/step - loss: 0.4332 - acc: 0.8021\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 349us/step - loss: 0.4264 - acc: 0.7891\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 419us/step - loss: 0.4269 - acc: 0.7982\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 353us/step - loss: 0.4293 - acc: 0.7969\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 368us/step - loss: 0.4195 - acc: 0.8099\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 410us/step - loss: 0.4240 - acc: 0.7904\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 471us/step - loss: 0.4258 - acc: 0.7943\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 445us/step - loss: 0.4237 - acc: 0.8008\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 529us/step - loss: 0.4279 - acc: 0.7956\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 445us/step - loss: 0.4261 - acc: 0.8151\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 415us/step - loss: 0.4406 - acc: 0.8021\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 496us/step - loss: 0.4317 - acc: 0.8073\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 370us/step - loss: 0.4301 - acc: 0.7943\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 397us/step - loss: 0.4208 - acc: 0.8008\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 1s 998us/step - loss: 0.4209 - acc: 0.8138\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 601us/step - loss: 0.4240 - acc: 0.8073\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 1s 1ms/step - loss: 0.4243 - acc: 0.7917\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 624us/step - loss: 0.4251 - acc: 0.7956\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 554us/step - loss: 0.4196 - acc: 0.7995\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 412us/step - loss: 0.4204 - acc: 0.8086\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 367us/step - loss: 0.4219 - acc: 0.8060\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 432us/step - loss: 0.4224 - acc: 0.7995\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 449us/step - loss: 0.4259 - acc: 0.8047\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 1s 775us/step - loss: 0.4195 - acc: 0.8047\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 620us/step - loss: 0.4152 - acc: 0.8164\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 427us/step - loss: 0.4177 - acc: 0.7982\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 476us/step - loss: 0.4165 - acc: 0.8073\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 622us/step - loss: 0.4287 - acc: 0.7917\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 508us/step - loss: 0.4231 - acc: 0.7982\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 434us/step - loss: 0.4206 - acc: 0.7917\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 1s 864us/step - loss: 0.4124 - acc: 0.7982\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 516us/step - loss: 0.4080 - acc: 0.8164\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 414us/step - loss: 0.4199 - acc: 0.7917\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 647us/step - loss: 0.4158 - acc: 0.7917\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 1s 873us/step - loss: 0.4181 - acc: 0.8060\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 513us/step - loss: 0.4118 - acc: 0.8060\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 541us/step - loss: 0.4058 - acc: 0.8086\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 488us/step - loss: 0.4166 - acc: 0.8021\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 569us/step - loss: 0.4133 - acc: 0.8008\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 560us/step - loss: 0.4057 - acc: 0.7995\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 552us/step - loss: 0.4098 - acc: 0.8151\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 1s 732us/step - loss: 0.4111 - acc: 0.8034\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 1s 748us/step - loss: 0.4142 - acc: 0.8099\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 1s 689us/step - loss: 0.4065 - acc: 0.8164\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 1s 674us/step - loss: 0.4177 - acc: 0.8008\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 1s 662us/step - loss: 0.4068 - acc: 0.8086\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 1s 750us/step - loss: 0.4142 - acc: 0.8047\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 622us/step - loss: 0.4233 - acc: 0.8034\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 545us/step - loss: 0.4282 - acc: 0.7904\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 570us/step - loss: 0.4089 - acc: 0.8125\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 621us/step - loss: 0.4059 - acc: 0.8138\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 638us/step - loss: 0.4050 - acc: 0.8138\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 1s 691us/step - loss: 0.4221 - acc: 0.8008\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 1s 767us/step - loss: 0.4243 - acc: 0.7878\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 1s 693us/step - loss: 0.4006 - acc: 0.8151\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 1s 794us/step - loss: 0.4146 - acc: 0.8099\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 421us/step - loss: 0.4075 - acc: 0.8138\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 473us/step - loss: 0.4077 - acc: 0.8190\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 385us/step - loss: 0.4043 - acc: 0.7995\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.4079 - acc: 0.8047\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 460us/step - loss: 0.4070 - acc: 0.8008\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 400us/step - loss: 0.4125 - acc: 0.8073\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 392us/step - loss: 0.4012 - acc: 0.8151 0s - loss: 0.2991 - acc: 0\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 462us/step - loss: 0.4055 - acc: 0.8151\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.4032 - acc: 0.8086\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 387us/step - loss: 0.4088 - acc: 0.8177\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 435us/step - loss: 0.4215 - acc: 0.7943 0s - loss: 0.3898 - acc: 0\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 490us/step - loss: 0.4027 - acc: 0.8138\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 472us/step - loss: 0.3986 - acc: 0.8086\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 554us/step - loss: 0.4013 - acc: 0.8164\n",
      "Epoch 100/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 468us/step - loss: 0.4040 - acc: 0.8216\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 511us/step - loss: 0.3952 - acc: 0.8164\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 433us/step - loss: 0.4131 - acc: 0.7995\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 420us/step - loss: 0.4017 - acc: 0.8099\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 479us/step - loss: 0.3960 - acc: 0.8177\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 411us/step - loss: 0.4041 - acc: 0.8164\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 398us/step - loss: 0.4040 - acc: 0.8151\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 420us/step - loss: 0.4220 - acc: 0.8047\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 393us/step - loss: 0.4075 - acc: 0.8151\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 367us/step - loss: 0.4076 - acc: 0.8060\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 367us/step - loss: 0.4095 - acc: 0.8125\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 375us/step - loss: 0.3985 - acc: 0.8099\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 371us/step - loss: 0.3944 - acc: 0.8151\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 453us/step - loss: 0.4037 - acc: 0.8008\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 468us/step - loss: 0.3949 - acc: 0.8242\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 445us/step - loss: 0.3992 - acc: 0.8086\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 413us/step - loss: 0.4255 - acc: 0.8164\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 481us/step - loss: 0.4018 - acc: 0.8125\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 391us/step - loss: 0.3990 - acc: 0.8216\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 396us/step - loss: 0.4232 - acc: 0.8021\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 399us/step - loss: 0.4021 - acc: 0.8125\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 349us/step - loss: 0.4012 - acc: 0.8125\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 372us/step - loss: 0.4041 - acc: 0.8073\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 425us/step - loss: 0.3988 - acc: 0.8229\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 403us/step - loss: 0.4120 - acc: 0.8073\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 309us/step - loss: 0.3963 - acc: 0.8177\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 351us/step - loss: 0.4006 - acc: 0.8112\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 388us/step - loss: 0.4014 - acc: 0.8151\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 346us/step - loss: 0.3987 - acc: 0.8021\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 409us/step - loss: 0.4002 - acc: 0.8190\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 356us/step - loss: 0.4033 - acc: 0.8125\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 353us/step - loss: 0.4177 - acc: 0.8073\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.4100 - acc: 0.8073\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 378us/step - loss: 0.3963 - acc: 0.8151\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 357us/step - loss: 0.3951 - acc: 0.8177\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 358us/step - loss: 0.4041 - acc: 0.8164\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 347us/step - loss: 0.3971 - acc: 0.8268\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 444us/step - loss: 0.3994 - acc: 0.8125\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 490us/step - loss: 0.4068 - acc: 0.8164 0s - loss: 0.4140 - acc: 0.8\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 446us/step - loss: 0.3998 - acc: 0.8190\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 366us/step - loss: 0.4011 - acc: 0.8125\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 398us/step - loss: 0.3891 - acc: 0.8177\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 384us/step - loss: 0.3924 - acc: 0.8060\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 348us/step - loss: 0.3998 - acc: 0.8190\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 387us/step - loss: 0.4007 - acc: 0.8177\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 399us/step - loss: 0.3969 - acc: 0.8125\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 392us/step - loss: 0.3969 - acc: 0.8099 0s - loss: 0.3998 - acc: 0.\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 370us/step - loss: 0.3937 - acc: 0.8125\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 466us/step - loss: 0.4041 - acc: 0.8125\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 347us/step - loss: 0.3960 - acc: 0.8125\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 406us/step - loss: 0.3991 - acc: 0.8164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1111b18d0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型\n",
    "#nb_epoch表示我们只训练150轮，batch_size表示每次批处理10个数据\n",
    "model.fit(X,Y,validation_split=0.33,epochs=150,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 108us/step\n",
      "acc: 82.16%\n"
     ]
    }
   ],
   "source": [
    "#评估模型\n",
    "scores=model.evaluate(X,Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
